{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BvZw349vxTBB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import dateutil\n",
        "import datetime\n",
        "import configparser\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end = datetime.date.today()\n",
        "start = datetime.date(2020, 1, 1)\n",
        "print('Start date: ' + str(start))\n",
        "print('End date: ' + str(end))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrxfgIh1-RRL",
        "outputId": "3c2e4e68-24a5-434c-c349-b4a17ee35bf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start date: 2020-01-01\n",
            "End date: 2022-03-23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "months_in_range = [x.split(' ') for x in pd.date_range(start, end, freq='MS').strftime(\"%Y %-m\").tolist()]\n",
        "months_in_range"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MxkIY3N-V_F",
        "outputId": "4b91c9a8-bc17-4dbc-b50e-ac961634c523"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['2020', '1'],\n",
              " ['2020', '2'],\n",
              " ['2020', '3'],\n",
              " ['2020', '4'],\n",
              " ['2020', '5'],\n",
              " ['2020', '6'],\n",
              " ['2020', '7'],\n",
              " ['2020', '8'],\n",
              " ['2020', '9'],\n",
              " ['2020', '10'],\n",
              " ['2020', '11'],\n",
              " ['2020', '12'],\n",
              " ['2021', '1'],\n",
              " ['2021', '2'],\n",
              " ['2021', '3'],\n",
              " ['2021', '4'],\n",
              " ['2021', '5'],\n",
              " ['2021', '6'],\n",
              " ['2021', '7'],\n",
              " ['2021', '8'],\n",
              " ['2021', '9'],\n",
              " ['2021', '10'],\n",
              " ['2021', '11'],\n",
              " ['2021', '12'],\n",
              " ['2022', '1'],\n",
              " ['2022', '2'],\n",
              " ['2022', '3']]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#configs = configparser.ConfigParser()\n",
        "#configs.read('config.ini')\n",
        "#YOUR_API_KEY = configs['NYT']['aaLRz4dlIAdYkcaKeoADrUjmgeaU9Omy']"
      ],
      "metadata": {
        "id": "zY4aTn-IoWix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_request(date):\n",
        "    '''Sends a request to the NYT Archive API for given date.'''\n",
        "    base_url = 'https://api.nytimes.com/svc/archive/v1/'\n",
        "    url = base_url + '/' + date[0] + '/' + date[1] + '.json?api-key=' + '4irjbJ6eLQseGkjqjLg8lFwpw1haGGNN'\n",
        "    response = requests.get(url).json()\n",
        "    time.sleep(6)\n",
        "    return response\n",
        "\n",
        "\n",
        "def is_valid(article, date):\n",
        "    '''An article is only worth checking if it is in range, and has a headline.'''\n",
        "    is_in_range = date > start and date < end\n",
        "    has_headline = type(article['headline']) == dict and 'main' in article['headline'].keys()\n",
        "    return is_in_range and has_headline\n",
        "\n",
        "\n",
        "def parse_response(response):\n",
        "    '''Parses and returns response as pandas data frame.'''\n",
        "    data = {'headline': [],  \n",
        "        'date': [], \n",
        "        'doc_type': [],\n",
        "        'material_type': [],\n",
        "        'snippet': [],\n",
        "        'keywords': []}\n",
        "    \n",
        "    articles = response['response']['docs'] \n",
        "    for article in articles: # For each article, make sure it falls within our date range\n",
        "        date = dateutil.parser.parse(article['pub_date']).date()\n",
        "        if is_valid(article, date):\n",
        "            data['date'].append(date)\n",
        "            data['headline'].append(article['headline']['main']) \n",
        "            if 'snippet' in article:\n",
        "                data['snippet'].append(article['snippet'])\n",
        "            else:\n",
        "                data['snippet'].append(None)\n",
        "            data['doc_type'].append(article['document_type'])\n",
        "            if 'type_of_material' in article: \n",
        "                data['material_type'].append(article['web_url'])\n",
        "            else:\n",
        "                data['material_type'].append(None)\n",
        "            keywords = [keyword['value'] for keyword in article['keywords'] if keyword['name'] == 'subject']\n",
        "            data['keywords'].append(keywords)\n",
        "    return pd.DataFrame(data) \n",
        "\n",
        "\n",
        "def get_data(dates):\n",
        "    '''Sends and parses request/response to/from NYT Archive API for given dates.'''\n",
        "    total = 0\n",
        "    print('Date range: ' + str(dates[0]) + ' to ' + str(dates[-1]))\n",
        "    if not os.path.exists('headlines'):\n",
        "        os.mkdir('headlines')\n",
        "    for date in dates:\n",
        "        response = send_request(date)\n",
        "        df = parse_response(response)\n",
        "        total += len(df)\n",
        "        df.to_csv('headlines/' + date[0] + '-' + date[1] + '.csv', index=False)\n",
        "        print('Saving headlines/' + date[0] + '-' + date[1] + '.csv...')\n",
        "    print('Number of articles collected: ' + str(total))"
      ],
      "metadata": {
        "id": "0pc3wAiN-gLr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_data(months_in_range)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh1H5o0--wjC",
        "outputId": "8d0b14ad-1930-475d-e4be-ada0287c510f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Date range: ['2020', '1'] to ['2022', '3']\n",
            "Saving headlines/2020-1.csv...\n",
            "Saving headlines/2020-2.csv...\n",
            "Saving headlines/2020-3.csv...\n",
            "Saving headlines/2020-4.csv...\n",
            "Saving headlines/2020-5.csv...\n",
            "Saving headlines/2020-6.csv...\n",
            "Saving headlines/2020-7.csv...\n",
            "Saving headlines/2020-8.csv...\n",
            "Saving headlines/2020-9.csv...\n",
            "Saving headlines/2020-10.csv...\n",
            "Saving headlines/2020-11.csv...\n",
            "Saving headlines/2020-12.csv...\n",
            "Saving headlines/2021-1.csv...\n",
            "Saving headlines/2021-2.csv...\n",
            "Saving headlines/2021-3.csv...\n",
            "Saving headlines/2021-4.csv...\n",
            "Saving headlines/2021-5.csv...\n",
            "Saving headlines/2021-6.csv...\n",
            "Saving headlines/2021-7.csv...\n",
            "Saving headlines/2021-8.csv...\n",
            "Saving headlines/2021-9.csv...\n",
            "Saving headlines/2021-10.csv...\n",
            "Saving headlines/2021-11.csv...\n",
            "Saving headlines/2021-12.csv...\n",
            "Saving headlines/2022-1.csv...\n",
            "Saving headlines/2022-2.csv...\n",
            "Saving headlines/2022-3.csv...\n",
            "Number of articles collected: 120850\n"
          ]
        }
      ]
    }
  ]
}